{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"164p7rG8BaUUhUAzxKpAvatsg8w4F6pPf","timestamp":1714409897871}],"authorship_tag":"ABX9TyNjPGrh5rW6AbNYF+LhWt5S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **Install Packages & Imports**"],"metadata":{"id":"vWR5c6Ove02g"}},{"cell_type":"code","source":["!pip install sentencepiece==0.2.0\n","!pip install quanto==0.0.11"],"metadata":{"id":"5HRrCHPGKefW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"MjKoXyz1KPkF","executionInfo":{"status":"ok","timestamp":1714417407017,"user_tz":-180,"elapsed":6,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}}},"outputs":[],"source":["import transformers\n","import torch\n","import sentencepiece as spm\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from memory_usage_helper import *"]},{"cell_type":"code","source":["import warnings\n","# Ignore specific UserWarnings related to max_length in transformers\n","warnings.filterwarnings(\"ignore\",\n","    message=\".*Using the model-agnostic default `max_length`.*\")"],"metadata":{"id":"HfE975ZXM96y","executionInfo":{"status":"ok","timestamp":1714417410896,"user_tz":-180,"elapsed":1238,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["helper = MemoryUsageHelper()"],"metadata":{"id":"j-ht89OVTA57","executionInfo":{"status":"ok","timestamp":1714417412043,"user_tz":-180,"elapsed":3,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### **Model without Quantize**"],"metadata":{"id":"NuHeDo_LfQeb"}},{"cell_type":"code","source":["model_name = \"google/flan-t5-small\"\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)"],"metadata":{"id":"lim3dCP_MBzW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Generation:**"],"metadata":{"id":"qU17F579fnN8"}},{"cell_type":"code","source":["input_text = \"Hello, my name is \"\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n","\n","outputs = model.generate(input_ids)\n","original_generation_output = tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"C9uGYQ4rMcOt","executionInfo":{"status":"ok","timestamp":1714417420581,"user_tz":-180,"elapsed":1440,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["**Model Size:**"],"metadata":{"id":"GPV0gJeRfpoR"}},{"cell_type":"code","source":["original_module_sizes = helper.compute_module_sizes(model)"],"metadata":{"id":"G__wF6p2Pk4l","executionInfo":{"status":"ok","timestamp":1714417421221,"user_tz":-180,"elapsed":4,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["##**Quantize the model by int8**"],"metadata":{"id":"8q0lyXkWQYxA"}},{"cell_type":"code","source":["from quanto import quantize, freeze"],"metadata":{"id":"opd3DvpHQeTL","executionInfo":{"status":"ok","timestamp":1714417423429,"user_tz":-180,"elapsed":1,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["quantize(model, weights=torch.int8, activations=None)"],"metadata":{"id":"8foo2P_XQau0","executionInfo":{"status":"ok","timestamp":1714417424780,"user_tz":-180,"elapsed":761,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["freeze(model)"],"metadata":{"id":"yJZcx_nmQhuz","executionInfo":{"status":"ok","timestamp":1714417426302,"user_tz":-180,"elapsed":1172,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["**Generation of quantize model:**"],"metadata":{"id":"I5RUQrELf9y2"}},{"cell_type":"code","source":["input_text = \"Hello, my name is \"\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n","\n","outputs = model.generate(input_ids)\n","quantized_generation_output = tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"5Z0zeZ4xQtbf","executionInfo":{"status":"ok","timestamp":1714417429528,"user_tz":-180,"elapsed":2225,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["**Quantize Model Size:**"],"metadata":{"id":"aAZzzhc_gB4L"}},{"cell_type":"code","source":["quantized_module_sizes = helper.compute_module_sizes(model)"],"metadata":{"id":"hXCokOL6Qnyy","executionInfo":{"status":"ok","timestamp":1714417429529,"user_tz":-180,"elapsed":4,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["##**Compare Results:**"],"metadata":{"id":"kx3oMvO_kf3h"}},{"cell_type":"markdown","source":["**Memory Usage:**"],"metadata":{"id":"vMBBxGNlk0h1"}},{"cell_type":"code","source":["print(f\"The original model size is {original_module_sizes[''] * 1e-9} GB\")\n","print(f\"The quantized model size is {quantized_module_sizes[''] * 1e-9} GB\")"],"metadata":{"id":"92NuPIRBkmEW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714417431734,"user_tz":-180,"elapsed":3,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}},"outputId":"5402c960-68e7-4d82-fb05-e7ec0d944ed7"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["The original model size is 0.307844608 GB\n","The quantized model size is 0.12682868 GB\n"]}]},{"cell_type":"markdown","source":["**Performance:**"],"metadata":{"id":"TGuNz8Vak3Qd"}},{"cell_type":"code","source":["print(f\"original model output: {original_generation_output}\")\n","print(f\"quantized model output: {quantized_generation_output}\")"],"metadata":{"id":"bOB5OE13lLLO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714417435863,"user_tz":-180,"elapsed":493,"user":{"displayName":"Shahar Benishay","userId":"10664071441584345351"}},"outputId":"48104d0c-3cc7-4341-918e-4207b7596de9"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["original model output: annie scott\n","quantized model output: annie scott\n"]}]}]}